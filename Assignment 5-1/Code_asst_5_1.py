# -*- coding: utf-8 -*-
"""Asst 5-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hXvgrQKOuwNxKxWclbh58RCSmVBqlPAk
"""

# Import Libraries
import pandas as pd
import numpy as np
import missingno as msno
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
import ipywidgets as widgets

# Load The dataset
employee_df = pd.read_csv('/content/layoffs.csv')

# @title Total Laid Off Over Time

employee_df.plot(x='date', y='total_laid_off', kind='line')

unique_countries = employee_df['country'].unique()
print(unique_countries)

employee_df

employee_df.head(5)

employee_df.tail(10)

employee_df.info()
# 35 features in total, each contains 1470 data points

employee_df.describe()

"""# Data Visualization"""

# Check if the columns exist before applying transformations
if 'percentage_laid_off' in employee_df.columns:
    employee_df['total_laid_off'] = employee_df['percentage_laid_off'].apply(lambda x: 1 if x == 'Yes' else 0)
else:
    print("Column 'percentage_laid_off' not found in DataFrame.")

employee_df.head(4)

# See if we have any missing data,
msno.matrix(employee_df, figsize=(5, 5), color=(0.2, 0.4, 0.6))

employee_df.hist(bins = 8, figsize = (5,5), color = 'y')

# Let's see how many employees left the company!
left_df        = employee_df[employee_df['total_laid_off'] == 1]
stayed_df      = employee_df[employee_df['percentage_laid_off'] == 0]

left_df.describe()

stayed_df.describe()

plt.figure(figsize=[5, 6])
sns.countplot(x='total_laid_off', data=employee_df)

employee_df.head(100)

# Assuming you have a DataFrame named 'data' with features and target variable
X = employee_df.drop(columns=['percentage_laid_off'])  # Drop the target column from features
y = employee_df['percentage_laid_off']  # Select the target column

# Now you can use train_test_split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)

from transformers import pipeline
unmasker = pipeline('fill-mask', model='distilbert-base-uncased')
unmasker("Hello I'm a [MASK] model.")

Classifier = pipeline(task= "sentiment-analysis", model = "distilbert-base-uncased-finetuned-sst-2-english")
Classifier('HR Dashboard')

!pip install gradio

from transformers import DistilBertForSequenceClassification, DistilBertTokenizer

# Load the pre-trained tokenizer
tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased-finetuned-sst-2-english")

# Load the pre-trained model
model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased-finetuned-sst-2-english")

employee_df.shape

# Check for NaN values in the 'country' column
nan_values = employee_df[employee_df['country'].isna()]

# Check the data type of values in the 'country' column
data_type = employee_df['country'].dtype

print("NaN Values:")
print(nan_values)
print("\nData Type:")
print(data_type)

employee_df

# @title Highest Percentage Laid Off by Industry

import matplotlib.pyplot as plt
employee_df.groupby('industry')['percentage_laid_off'].mean().sort_values(ascending=False).plot(kind='bar')
plt.xlabel('Industry')
_ = plt.ylabel('Average Percentage Laid Off')

# @title Total companies laying off employees per industry

employee_df.groupby('industry')['location'].count().plot(kind='bar')

y_train

# Convert 'percentage_laid_off' to binary labels
employee_df['total_laid_off'] = employee_df['percentage_laid_off'].apply(lambda x: 1 if x == 'Yes' else 0)

# Drop unnecessary columns
X = employee_df.drop(columns=['percentage_laid_off'])
y = employee_df['total_laid_off']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Define categorical and numerical columns
categorical_cols = ['location', 'industry', 'date', 'country']  # Assuming these are categorical columns
numerical_cols = [col for col in X_train.columns if col not in categorical_cols]

# Create a column transformer
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_cols),
        ('cat', OneHotEncoder(drop='if_binary', sparse=False, handle_unknown='ignore'), categorical_cols)
    ],
    remainder='passthrough'
)

# Create KNN model with CalibratedClassifierCV
knn_model = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', CalibratedClassifierCV(KNeighborsClassifier()))
])

# Train the model
knn_model.fit(X_train, y_train)

# Evaluate the model
y_pred = knn_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Calculate precision and recall
precision = precision_score(y_test, y_pred, zero_division=0)
recall = recall_score(y_test, y_pred, zero_division=0)

print("Precision:", precision)
print("Recall:", recall)

# Calculate ROC AUC if possible
try:
    y_pred_prob = knn_model.predict_proba(X_test)[:, 1]  # Getting probabilities using predict_proba
    roc_auc = roc_auc_score(y_test, y_pred_prob)
    print("ROC AUC Score:", roc_auc)

    # Plot ROC curve
    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], linestyle='--', color='red')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend()
    plt.show()
except Exception as e:
    print("Cannot calculate ROC AUC:", e)

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(y))
disp.plot(cmap='Blues')
plt.title('Confusion Matrix')
plt.show()

# install dependencies
!pip install diffusers
!pip install transformers

from transformers import pipeline
unmasker = pipeline('fill-mask', model='distilbert-base-uncased')
unmasker("Hello I'm a [MASK] model.")

from transformers import DistilBertTokenizer, TFDistilBertModel
tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
model = TFDistilBertModel.from_pretrained("distilbert-base-uncased")
text = "HR Dashboard."
encoded_input = tokenizer(text, return_tensors='tf')
output = model(encoded_input)

Classifier = pipeline(task= "sentiment-analysis", model = "distilbert-base-uncased-finetuned-sst-2-english")
Classifier('HR Dashboard')

!pip install gradio

from transformers import DistilBertForSequenceClassification, DistilBertTokenizer

# Load the pre-trained tokenizer
tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased-finetuned-sst-2-english")

# Load the pre-trained model
model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased-finetuned-sst-2-english")

# Function to update bar chart based on location selection
def update_bar_chart(location):
    plt.figure(figsize=(10, 6))
    df_location = employee_df[employee_df['location'] == location]
    plt.bar(df_location['industry'], df_location['total_laid_off'])
    plt.title(f'Total Employees Laid Off in {location}')
    plt.xlabel('Industry')
    plt.ylabel('Total Laid Off')
    plt.xticks(rotation=45)
    plt.show()

unique_countries = employee_df['country'].unique()
print(unique_countries)

# Use a pipeline as a high-level helper
from transformers import pipeline

pipe = pipeline("text-classification", model="distilbert/distilbert-base-uncased-finetuned-sst-2-english")

# Load model directly
from transformers import AutoTokenizer, AutoModelForSequenceClassification

tokenizer = AutoTokenizer.from_pretrained("distilbert/distilbert-base-uncased-finetuned-sst-2-english")
model = AutoModelForSequenceClassification.from_pretrained("distilbert/distilbert-base-uncased-finetuned-sst-2-english")

! pip install gradio

import gradio as gr

def get_sentiment_response(query):
    # Implement your sentiment analysis and response generation logic here
    response = "The sentiments of the people laid off may vary. Some may feel depressed and resentful towards their company for their decision to lay them off. Others may feel survivor's guilt and feel grateful for still having a job. Some may also feel motivated to find a new job, while others may feel disheartened by the job market. Overall, the sentiments of individuals who have been laid off may be a mix of emotions such as anger, sadness, uncertainty, and hope."
    return response

iface = gr.Interface(fn=get_sentiment_response,
                     inputs=gr.Textbox(label="Enter your query:"),
                     outputs=gr.Textbox(label="Result:"),
                     title="Let's Talk with Data!")

iface.launch()